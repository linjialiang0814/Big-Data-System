{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2kGijdiREMQ"
      },
      "source": [
        "# CS4225/CS5425 Assignment 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2pANZfr7427",
        "outputId": "d1d3c333-95b8-4ee7-b1cb-80d8369d2966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsEszpR0CFcY",
        "outputId": "bc3abcf8-fafa-47d8-ce48-dbd39fa6ae5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.12/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# For Google Colaboratory\n",
        "!pip install pyspark py4j\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRh7iyJLCEOL",
        "outputId": "725708b8-4803-4e64-e20c-a5b861fcc451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/CS4225/Assignment_2\n"
          ]
        }
      ],
      "source": [
        "# For Google Colaboratory\n",
        "import sys, os\n",
        "if 'google.colab' in sys.modules:\n",
        "    # mount google drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    path_to_file = '/content/gdrive/MyDrive/CS4225/Assignment_2/'\n",
        "    os.chdir(path_to_file)\n",
        "    !pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov6DQ7BjREMS"
      },
      "source": [
        "## 1. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_kv-JfSREMS"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load dataset"
      ],
      "metadata": {
        "id": "7fFe10DJw1_H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOFLTCsV7HuJ"
      },
      "outputs": [],
      "source": [
        "transactions_path = 'file:/content/gdrive/MyDrive/CS4225/Assignment_2/transactions/transactions_*.csv'\n",
        "transaction_items_path = 'file:/content/gdrive/MyDrive/CS4225/Assignment_2/transaction_items/transaction_items_*.csv'\n",
        "users_path = 'file:/content/gdrive/MyDrive/CS4225/Assignment_2/users/users_*.csv'\n",
        "stores_path = 'file:/content/gdrive/MyDrive/CS4225/Assignment_2/stores/stores.csv'\n",
        "menu_path = 'file:/content/gdrive/MyDrive/CS4225/Assignment_2/menu_items/menu_items.csv'\n",
        "\n",
        "transactions = spark.read.csv(transactions_path, header=True, inferSchema=True)\n",
        "transaction_items = spark.read.csv(transaction_items_path, header=True, inferSchema=True)\n",
        "users = spark.read.csv(users_path, header=True, inferSchema=True)\n",
        "stores = spark.read.csv(stores_path, header=True, inferSchema=True)\n",
        "menu = spark.read.csv(menu_path, header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "date"
      ],
      "metadata": {
        "id": "0kG46D6pxAkO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwxDgOAS7Hq7"
      },
      "outputs": [],
      "source": [
        "transactions = transactions.withColumn(\"transaction_date\", to_date(col(\"created_at\")))\n",
        "transaction_items = transaction_items.withColumn(\"transaction_date\", to_date(col(\"created_at\")))\n",
        "\n",
        "transactions = transactions.na.drop(subset=[\"transaction_date\", \"original_amount\", \"store_id\"])\n",
        "transaction_items = transaction_items.na.drop(subset=[\"transaction_date\", \"subtotal\", \"item_id\", \"quantity\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "store_sales_T"
      ],
      "metadata": {
        "id": "dK6TAStTxJdO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cuvy3Khe7HnN",
        "outputId": "09232887-679b-411b-e708-b322d4cf2f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------------+-------------+\n",
            "|store_id|transaction_date|store_sales_T|\n",
            "+--------+----------------+-------------+\n",
            "|      10|      2025-05-27|      67032.5|\n",
            "|       2|      2025-03-16|      65408.5|\n",
            "|       7|      2025-05-07|      65853.5|\n",
            "|       5|      2025-05-16|      68606.0|\n",
            "|       1|      2025-03-30|      64701.5|\n",
            "+--------+----------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7310"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "daily_sales = transactions.groupBy(\"store_id\", \"transaction_date\").agg(\n",
        "    sum(\"original_amount\").alias(\"store_sales_T\")\n",
        ")\n",
        "daily_sales.show(5)\n",
        "daily_sales.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "store_sales_T-1"
      ],
      "metadata": {
        "id": "vbPbWPwaxPPs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijKj6UKO7Oqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ac85a8-d0a6-469b-c6be-38a3c2149001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------------+-------------+---------------+\n",
            "|store_id|transaction_date|store_sales_T|store_sales_T-1|\n",
            "+--------+----------------+-------------+---------------+\n",
            "|       1|      2023-07-02|      66456.0|        67301.5|\n",
            "|       1|      2023-07-03|      67628.5|        66456.0|\n",
            "|       1|      2023-07-04|      65243.5|        67628.5|\n",
            "|       1|      2023-07-05|      69179.0|        65243.5|\n",
            "|       1|      2023-07-06|      66620.5|        69179.0|\n",
            "+--------+----------------+-------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7300"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from pyspark.sql.window import Window\n",
        "\n",
        "window = Window.partitionBy(\"store_id\").orderBy(\"transaction_date\")#核心\n",
        "daily_sales = daily_sales.withColumn(\"store_sales_T-1\", lag(\"store_sales_T\").over(window))\n",
        "daily_sales = daily_sales.filter(col(\"store_sales_T-1\").isNotNull())\n",
        "\n",
        "daily_sales.show(5)\n",
        "daily_sales.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "drink types"
      ],
      "metadata": {
        "id": "jEBzI4r1xTWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transactions_join = transactions.select(\"transaction_id\", \"store_id\")\n",
        "transaction_items = transaction_items.join(transactions_join, on=\"transaction_id\", how=\"left\")"
      ],
      "metadata": {
        "id": "6M9O-gLT7F_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "menu = menu.select(col(\"item_id\"), col(\"item_name\").alias(\"drink_name\"))\n",
        "transaction_items = transaction_items.join(menu, on=\"item_id\", how=\"left\")"
      ],
      "metadata": {
        "id": "4lghOoXb9ZLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VwpO6307Hi_",
        "outputId": "69e7777b-6786-4a56-fc45-f6fee2742d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------------+--------+---------+------+----------+----------+------+-------------+------------+\n",
            "|store_id|transaction_date|Espresso|Americano| Latte|Cappuccino|Flat White| Mocha|Hot Chocolate|Matcha Latte|\n",
            "+--------+----------------+--------+---------+------+----------+----------+------+-------------+------------+\n",
            "|       2|      2024-03-23|  5928.0|   6797.0|8216.0|    7952.0|    9558.0|9424.0|       9738.0|     10050.0|\n",
            "|       4|      2024-08-29|  6126.0|   6566.0|7432.0|    7136.0|    8838.0|8920.5|       9234.0|      9580.0|\n",
            "|       7|      2025-02-21|  5982.0|   7014.0|7848.0|    7904.0|    8982.0|9063.0|       9009.0|      9970.0|\n",
            "|       2|      2025-04-10|  6546.0|   7014.0|8232.0|    7584.0|    8955.0|9956.0|       8388.0|      9370.0|\n",
            "|       8|      2024-01-27|  5844.0|   7042.0|8600.0|    8008.0|    9081.0|9471.5|      10296.0|     10540.0|\n",
            "+--------+----------------+--------+---------+------+----------+----------+------+-------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7310"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "drink_sales = transaction_items.groupBy(\"store_id\", \"transaction_date\", \"drink_name\") \\\n",
        "    .agg(sum(\"subtotal\").alias(\"item_sales\"))\n",
        "\n",
        "drink_types = [\"Espresso\", \"Americano\", \"Latte\", \"Cappuccino\", \"Flat White\", \"Mocha\", \"Hot Chocolate\", \"Matcha Latte\"]\n",
        "\n",
        "drink_sales_new = drink_sales.groupBy(\"store_id\", \"transaction_date\") \\\n",
        "    .pivot(\"drink_name\", drink_types).sum(\"item_sales\")\n",
        "drink_sales_new = drink_sales_new.fillna(0)\n",
        "\n",
        "drink_sales_new.show(5)\n",
        "drink_sales_new.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gender & average age"
      ],
      "metadata": {
        "id": "NhODqZVAxcXk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5orJGk9FSHzF",
        "outputId": "a2422623-3f44-4fa8-f331-1852410d51ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------------+------------+--------------+---------------+-----------+\n",
            "|store_id|transaction_date|num_male_T-1|num_female_T-1|num_unknown_T-1|avg_age_T-1|\n",
            "+--------+----------------+------------+--------------+---------------+-----------+\n",
            "|       1|      2023-09-14|          17|            13|           2035|       34.0|\n",
            "|      10|      2025-05-27|         996|           982|             24|       39.0|\n",
            "|       1|      2023-09-16|          12|             6|           1905|       36.0|\n",
            "|       8|      2023-09-17|           5|             9|           1908|       40.0|\n",
            "|       1|      2024-12-31|         949|           996|             93|       38.0|\n",
            "+--------+----------------+------------+--------------+---------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7310"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "users = users.withColumn(\"birthdate\", to_date(col(\"birthdate\")))\n",
        "users = users.withColumn(\"registered_date\", to_date(col(\"registered_at\")))\n",
        "\n",
        "transactions_users = transactions.join(users, on=\"user_id\", how=\"left\")\n",
        "\n",
        "transactions_users = transactions_users.withColumn(\n",
        "    \"age_at_transaction\",\n",
        "    (datediff(col(\"transaction_date\"), col(\"birthdate\")) / 365).cast(\"double\")\n",
        ")\n",
        "\n",
        "user_stats = transactions_users.groupBy(\"store_id\", \"transaction_date\").agg(\n",
        "    count(when(col(\"gender\") == \"male\", True)).alias(\"num_male_T-1\"),\n",
        "    count(when(col(\"gender\") == \"female\", True)).alias(\"num_female_T-1\"),\n",
        "    count(when(col(\"gender\").isNull(), True)).alias(\"num_unknown_T-1\"),\n",
        "    round(avg(\"age_at_transaction\")).alias(\"avg_age_T-1\")\n",
        ")\n",
        "\n",
        "user_stats.show(5)\n",
        "user_stats.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "final table"
      ],
      "metadata": {
        "id": "uQcX5Qks2h_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1X576efUcCP",
        "outputId": "229e8de2-6119-4f27-fe48-87c645741771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transactions: 7300 rows\n"
          ]
        }
      ],
      "source": [
        "final = daily_sales.join(drink_sales_new, on=[\"store_id\",\"transaction_date\"], how=\"left\")\n",
        "final = final.join(user_stats, on=[\"store_id\",\"transaction_date\"], how=\"left\")\n",
        "\n",
        "final = final.fillna(0)\n",
        "\n",
        "final = final.orderBy(col(\"store_id\").asc(), col(\"transaction_date\").asc())\n",
        "\n",
        "final_output_path = 'file:/content/gdrive/MyDrive/CS4225/Assignment_2/final.csv'\n",
        "final.write.csv(final_output_path, header=True, mode=\"overwrite\")\n",
        "\n",
        "print(\"Transactions:\",final.count(), \"rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k7zEW137N1w"
      },
      "source": [
        "## 2. Build ML Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reload dataset"
      ],
      "metadata": {
        "id": "tP3htlt52MsK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwDHJ4Jq7Qeh",
        "outputId": "cc8d5268-25a6-4ece-fa35-11cebec1a9a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 7300\n",
            "Columns: ['store_id', 'transaction_date', 'store_sales_T', 'store_sales_T-1', 'Espresso', 'Americano', 'Latte', 'Cappuccino', 'Flat White', 'Mocha', 'Hot Chocolate', 'Matcha Latte', 'num_male_T-1', 'num_female_T-1', 'num_unknown_T-1', 'avg_age_T-1']\n",
            "+--------+----------------+-------------+---------------+--------+---------+------+----------+----------+-------+-------------+------------+------------+--------------+---------------+-----------+\n",
            "|store_id|transaction_date|store_sales_T|store_sales_T-1|Espresso|Americano| Latte|Cappuccino|Flat White|  Mocha|Hot Chocolate|Matcha Latte|num_male_T-1|num_female_T-1|num_unknown_T-1|avg_age_T-1|\n",
            "+--------+----------------+-------------+---------------+--------+---------+------+----------+----------+-------+-------------+------------+------------+--------------+---------------+-----------+\n",
            "|       1|      2023-07-02|      66456.0|        67301.5|  5754.0|   7357.0|8112.0|    7912.0|    9522.0| 9633.0|       8316.0|      9850.0|           2|             0|           1980|       50.0|\n",
            "|       1|      2023-07-03|      67628.5|        66456.0|  6168.0|   7119.0|8032.0|    7504.0|    9333.0| 9680.5|       9972.0|      9820.0|           1|             1|           2008|       54.0|\n",
            "|       1|      2023-07-04|      65243.5|        67628.5|  6126.0|   6223.0|7704.0|    7792.0|    8658.0|10326.5|       9144.0|      9270.0|           3|             1|           1953|       33.0|\n",
            "|       1|      2023-07-05|      69179.0|        65243.5|  6288.0|   7105.0|8504.0|    8520.0|    8928.0| 9785.0|       9189.0|     10860.0|           2|             3|           2063|       36.0|\n",
            "|       1|      2023-07-06|      66620.5|        69179.0|  5982.0|   7133.0|6960.0|    8520.0|    9198.0| 9604.5|       9063.0|     10160.0|           4|             2|           2015|       27.0|\n",
            "+--------+----------------+-------------+---------------+--------+---------+------+----------+----------+-------+-------------+------------+------------+--------------+---------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "final = spark.read.csv(\n",
        "    \"file:/content/gdrive/MyDrive/CS4225/Assignment_2/final.csv\",\n",
        "    header=True,\n",
        "    inferSchema=True\n",
        ")\n",
        "\n",
        "print(\"Rows:\", final.count())\n",
        "print(\"Columns:\", final.columns)\n",
        "\n",
        "final.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train and test split"
      ],
      "metadata": {
        "id": "qDNjDBDF2EAc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARz4mxwZ7QYd",
        "outputId": "d9f5a902-736f-4b1a-ed0c-06fcf8e36f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training rows: 5490\n",
            "Testing rows: 1810\n"
          ]
        }
      ],
      "source": [
        "train_data = final.filter((col(\"transaction_date\") >= \"2023-07-01\") &\n",
        "                           (col(\"transaction_date\") <= \"2024-12-31\"))\n",
        "\n",
        "test_data = final.filter((col(\"transaction_date\") >= \"2025-01-01\") &\n",
        "                          (col(\"transaction_date\") <= \"2025-06-30\"))\n",
        "\n",
        "print(\"Training rows:\", train_data.count())\n",
        "print(\"Testing rows:\", test_data.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pipeline"
      ],
      "metadata": {
        "id": "lpF5g9Pg2X8T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVOO579v7QVP",
        "outputId": "6428f4a2-b9b5-4489-c717-54d7eefa2cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features: ['store_id', 'store_sales_T-1', 'Espresso', 'Americano', 'Latte', 'Cappuccino', 'Flat White', 'Mocha', 'Hot Chocolate', 'Matcha Latte', 'num_male_T-1', 'num_female_T-1', 'num_unknown_T-1', 'avg_age_T-1']\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "feature_selected = [c for c, dtype in final.dtypes if dtype in ('double', 'int') and c not in ['store_sales_T']]\n",
        "print(\"Selected features:\", feature_selected)\n",
        "\n",
        "assembler = VectorAssembler(inputCols=feature_selected, outputCol=\"features\")\n",
        "\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
        "\n",
        "rf = RandomForestRegressor(featuresCol=\"scaled_features\", labelCol=\"store_sales_T\")\n",
        "\n",
        "pipeline = Pipeline(stages=[assembler, scaler, rf])\n",
        "\n",
        "model = pipeline.fit(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLT8p7MR7SS9"
      },
      "source": [
        "## 3. Evaluate ML Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPFBKyyD7TxV",
        "outputId": "da453903-1d45-46c9-fa35-1b7501e36fab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MAE: 596.071688481766\n",
            "Testing MAE: 624.0888361744389\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "train_pred = model.transform(train_data)\n",
        "test_pred = model.transform(test_data)\n",
        "\n",
        "evaluator = RegressionEvaluator(labelCol=\"store_sales_T\", predictionCol=\"prediction\", metricName=\"mae\")\n",
        "\n",
        "train_mae = evaluator.evaluate(train_pred)\n",
        "test_mae = evaluator.evaluate(test_pred)\n",
        "\n",
        "print(\"Training MAE:\", train_mae)\n",
        "print(\"Testing MAE:\", test_mae)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}